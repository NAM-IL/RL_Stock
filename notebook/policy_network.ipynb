{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RLTrader_Module_diagram\n",
    "> ![LSTM_NeuralNetwork](img/RLTrader_Module_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import modul & library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, LSTM, Dense, BatchNormalization\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PolicyNetwork class definitation\n",
    "> ![PolicyNetwork class](img/PolicyNetwork__class.png \"PolicyNetwork class\") </br>\n",
    "> ![LSTM_NeuralNetwork](img/LSTM_NeuralNetwork.png \"LSTM_NeuralNetwork\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyNetwork:\n",
    "    def __init__(self, input_dim=0, output_dim=0, lr=0.01):\n",
    "        self.input_dim = input_dim\n",
    "        self.lr = lr\n",
    "        self.prob = None\n",
    "        \n",
    "        # LSTM 신경망\n",
    "        self.model = Sequential()\n",
    "        # returns a sequence of vectors of dimension 256\n",
    "        self.model.add(LSTM(256, input_shape = (1, input_dim), \n",
    "                                 return_sequences = True, stateful = False, dropout = 0.5))\n",
    "        self.model.add(BatchNormalization())\n",
    "        # returns a sequence of vectors of dimension 256\n",
    "        self.model.add(LSTM(256, return_sequences = True, stateful = False, dropout = 0.5))\n",
    "        self.model.add(BatchNormalization())\n",
    "        # return a single vector of dimension 256\n",
    "        self.model.add(LSTM(256, return_sequences = False, stateful = False, dropout = 0.5))\n",
    "        self.model.add(BatchNormalization())\n",
    "        slef.model.add(Dense(output_dim))\n",
    "        self.model.add(Activation('sigmoid'))\n",
    "        \n",
    "        # configure learning process with .compile():\n",
    "        # 최적화 알고리즘(Optimazation algorithm) - 확률적 경사 하강법(SGD)\n",
    "        # 기본 학습속도(Learning rate, LR) - 0.01\n",
    "        self.model.compile(optimizer = SGD(lr=lr), loss = 'mse')\n",
    "        \n",
    "    # class member functions\n",
    "    # self.prob 변수를 초기화\n",
    "    def reset(self):\n",
    "        self.prob = None\n",
    "\n",
    "    # 신경망을 통해서 학습 데이터와 에이전트 상태를 합한 17차원의 입력을 받아서 매수와 매도가 수익을\n",
    "    # 높일 것으로 판단되는 확률을 구함.\n",
    "    def predict(self, sample):\n",
    "        # 여러 샘풀을 한꺼번에 받아서 신경망의 출력을 반환\n",
    "        self.prob = self.model.predict(np.array(sample).reshape(1, -1, self.input_dim))[0]\n",
    "        return self.prob\n",
    "\n",
    "    def train_on_batch(self, x, y):\n",
    "        return self.model.train_on_batch(x, y)\n",
    "\n",
    "    def save_model(self, model_path):\n",
    "        if model_path is not None and self.model is not None:\n",
    "            self.model.save_weights(model_path, overwrite = True)\n",
    "\n",
    "    def load_model(self, model_path):\n",
    "        if model_path is not None:\n",
    "            self.model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# numpy\n",
    ">* [numpy.ndarray.reshape](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.reshape.html) : Gives a new shape to an array without changing its data.\n",
    "> ![numpy.ndarray.reshape](img/numpy.ndarray.reshape.png \"numpy.ndarray.reshape method\") </br>\n",
    "\n",
    ">* [numpy.reshape](https://docs.scipy.org/doc/numpy-1.15.1/reference/generated/numpy.reshape.html) : Gives a new shape to an array without changing its data.\n",
    "> ![numpy.reshape](img/numpy.reshape.png \"numpy.reshape method\") </br>\n",
    "\n",
    "\n",
    "# Model class API\n",
    ">## Methods\n",
    "* [compile](https://keras.io/models/model/#model-class-api) : Configures the model for training.\n",
    "><pre>compile(optimizer, loss=None, metrics=None, loss_weights=None, sample_weight_mode=None, weighted_metrics=None, target_tensors=None)\n",
    "</pre>\n",
    "> ![compile](img/compile.png \"compile method\") </br>\n",
    "\n",
    ">* [fit](https://keras.io/models/model/#model-class-api) : Trains the model for a given number of epochs (iterations on a dataset).\n",
    "><pre>fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, \n",
    "          callbacks=None, validation_split=0.0, validation_data=None, \n",
    "          shuffle=True, class_weight=None, sample_weight=None, \n",
    "          initial_epoch=0, steps_per_epoch=None, validation_steps=None)\n",
    "</pre>\n",
    "> ![fit](img/fit_1.png \"fit method\") </br>\n",
    "> ![fit](img/fit_2.png \"fit method\") </br>\n",
    "\n",
    ">* [predict](https://keras.io/models/model/#model-class-api) : Generates output predictions for the input samples.\n",
    "><pre>predict(x, batch_size=None, verbose=0, steps=None)\n",
    "</pre>\n",
    "> ![predict](img/predict.png \"predict method\") </br>\n",
    "\n",
    ">* [train_on_batch](https://keras.io/models/model/#model-class-api) : Runs a single gradient update on a single batch of data.\n",
    "><pre>train_on_batch(x, y, sample_weight=None, class_weight=None)\n",
    "</pre>\n",
    "> ![train_on_batch](img/train_on_batch.png \"train_on_batch method\") </br>\n",
    "\n",
    ">* [predict_on_batch](https://keras.io/models/model/#model-class-api) : Returns predictions for a single batch of samples.\n",
    "><pre>predict_on_batch(x)\n",
    "</pre>\n",
    "> ![predict_on_batch](img/predict_on_batch.png \"predict_on_batch method\") </br>\n",
    "\n",
    "\n",
    ">* [BatchNormalization](https://keras.io/layers/normalization/) : Batch normalization layer (Ioffe and Szegedy, 2014).\n",
    "><pre>Normalize the activations of the previous layer at each batch, i.e. applies a transformation that maintains the mean activation close to 0 and the activation standard deviation close to 1.\n",
    "</pre>\n",
    "><pre> keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001, center=True, scale=True, beta_initializer='zeros', gamma_initializer='ones', moving_mean_initializer='zeros', moving_variance_initializer='ones', beta_regularizer=None, gamma_regularizer=None, beta_constraint=None, gamma_constraint=None)\n",
    "</pre>\n",
    "> ![BatchNormalization](img/BatchNormalization.png \"BatchNormalization method\") </br>\n",
    "\n",
    "\n",
    ">* [Dense](https://keras.io/layers/core/) :  Just your regular densely-connected NN layer.\n",
    "><pre>Dense implements the operation: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is True).\n",
    "</pre>\n",
    "> ![Dense](img/Dense.png \"Dense method\") </br>\n",
    "\n",
    ">* [Activation](https://keras.io/layers/core/) : Applies an activation function to an output.\n",
    "> ![Activation](img/Activation.png \"Activation method\") </br>\n",
    "\n",
    ">* [Dropout](https://keras.io/layers/core/) : Applies Dropout to the input.\n",
    "><pre>Dropout consists in randomly setting a fraction rate of input units to 0 at each update during training time, which helps prevent overfitting.\n",
    "</pre>\n",
    "> ![Dropout](img/Dropout.png \"Dropout method\") </br>\n",
    "\n",
    ">* [save_weights](https://keras.io/models/about-keras-models/#about-keras-models) : saves the weights of the model as a HDF5 file.\n",
    "> ![save_weights](img/save_weights.png \"save_weights method\") </br>\n",
    "\n",
    ">* [SGD](https://keras.io/optimizers/#usage-of-optimizers) : Stochastic gradient descent optimizer.\n",
    "><pre>keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "</pre>\n",
    "><pre>Includes support for momentum, learning rate decay, and Nesterov momentum.\n",
    "</pre>\n",
    "> ![SGD](img/SGD.png \"SGD method\") </br>\n",
    "\n",
    ">* [Adam](https://keras.io/optimizers/#usage-of-optimizers) : Adam optimizer.\n",
    "><pre>Default parameters follow those provided in the original paper.\n",
    "</pre>\n",
    "> ![Adam](img/Adam.png \"Adam method\") </br>\n",
    "><pre>References</pre>\n",
    ">> * [Adam - A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980v8)\n",
    ">> * [On the Convergence of Adam and Beyond](https://openreview.net/forum?id=ryQu7f-RZ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reference\n",
    "* [Stateful LSTM model training in Keras](https://fairyonice.github.io/Stateful-LSTM-model-training-in-Keras.html)\n",
    "* [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)\n",
    "* [Keras: The Python Deep Learning library](https://keras.io/)\n",
    ">* [Keras: Deep Learning for humans](https://github.com/keras-team/keras)\n",
    ">* [About Keras models](https://keras.io/models/about-keras-models/#about-keras-models)\n",
    ">* [Getting started with the Keras Sequential model](https://keras.io/getting-started/sequential-model-guide/)\n",
    ">* [The Sequential model API](https://keras.io/models/sequential/)\n",
    ">* [Usage of optimizers](https://keras.io/optimizers/#usage-of-optimizers)\n",
    ">* [BatchNormalization](https://keras.io/layers/normalization/)\n",
    ">* [Model class API](https://keras.io/models/model/#model-class-api)\n",
    ">* [Usage of activations](https://keras.io/activations/)\n",
    ">* [Docs » Layers » Core](https://keras.io/layers/core/)\n",
    "* [파이썬과 케라스를 이용한 딥러닝/강화학습 주식투자](https://github.com/quantylab/rltrader)  \n",
    "* [Install the TensorFlow pip package](https://www.tensorflow.org/install/pip?hl=ko) \n",
    "* [TensorFlow-v1.0.0 + Keras 설치 (Windows/Linux/macOS)](http://tmmse.xyz/2017/03/01/tensorflow-keras-installation-windows-linux-macos/) \n",
    "* [TensorFlow Probability](https://www.tensorflow.org/probability/install?hl=ko)  \n",
    "* [Getting Started with Gym](https://gym.openai.com/docs/) \n",
    "* [마크다운 markdown 작성법](https://gist.github.com/ihoneymon/652be052a0727ad59601)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
